AFST was created with the clear intention of recognizing potential abusive households and removing the child from that situation before any harm could be done. Although, there come some clear flaws with this system. It will never be 100% accurate and will often target poor households and people of color. Why does it do this? Since it is based on previous data the system is inherently biased, children from low-income and POC households will have a higher danger level. Still, AFST can be a great tool when used correctly, but do these pros outweigh the cons? There must be a better way to develop a more accurate algorithm, or is everywhere possible algorithm doomed to have some type of bias?